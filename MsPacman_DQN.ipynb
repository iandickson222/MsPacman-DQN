{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MsPacman DQN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOssjzVnJW3fBRYVMFpzU9+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iandickson222/MsPacman-DQN/blob/main/MsPacman_DQN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smQqJYQAwPJK",
        "outputId": "4582e76e-ddad-4cc5-d3e1-810aef9d5983"
      },
      "source": [
        "%%bash\n",
        "sudo apt-get install -y xvfb ffmpeg\n",
        "pip install -q 'imageio==2.4.0'\n",
        "pip install -q pyvirtualdisplay\n",
        "pip install -q tf-agents"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following NEW packages will be installed:\n",
            "  xvfb\n",
            "0 upgraded, 1 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 784 kB of archives.\n",
            "After this operation, 2,270 kB of additional disk space will be used.\n",
            "Ign:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8\n",
            "Err:1 http://security.ubuntu.com/ubuntu bionic-updates/universe amd64 xvfb amd64 2:1.19.6-1ubuntu4.8\n",
            "  404  Not Found [IP: 91.189.88.152 80]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "E: Failed to fetch http://security.ubuntu.com/ubuntu/pool/universe/x/xorg-server/xvfb_1.19.6-1ubuntu4.8_amd64.deb  404  Not Found [IP: 91.189.88.152 80]\n",
            "E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7aR8qpowg53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d047501-6c05-4cc4-a18a-6da0269e4a0f"
      },
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "import os\n",
        "import collections\n",
        "import gym\n",
        "\n",
        "import tf_agents\n",
        "import tensorflow as tf\n",
        "from tf_agents.environments import suite_atari\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXvbkzHmlwXA"
      },
      "source": [
        "class ObservationCollector(gym.Wrapper):\n",
        "\n",
        "  def __init__(self, env):\n",
        "    super(ObservationCollector, self).__init__(env)\n",
        "    self._observations = collections.deque(maxlen=50000)\n",
        "    \n",
        "  def step(self, action):\n",
        "    observation, accumulated_reward, is_terminal, info = self.env.step(action)\n",
        "    self._observations.append(observation) \n",
        "    return observation, accumulated_reward, is_terminal, info\n",
        "  \n",
        "  def reset(self):\n",
        "    observation = self.env.reset()\n",
        "    self._observations.clear()\n",
        "    self._observations.append(observation)\n",
        "    return observation\n",
        "  \n",
        "  def return_observations(self):\n",
        "    return self._observations"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W27iRprPvPU"
      },
      "source": [
        "class Normalizer(tf_agents.environments.wrappers.PyEnvironmentBaseWrapper):\n",
        "\n",
        "  def __init__(self, env, start_assistance = False):\n",
        "    super(Normalizer, self).__init__(env)\n",
        "    self._env = env\n",
        "    self._observation_spec = tf_agents.specs.BoundedArraySpec(\n",
        "        shape = env.observation_spec().shape,\n",
        "        dtype = np.float32,\n",
        "        minimum = 0.0,\n",
        "        maximum = 1.0,\n",
        "        name = env.observation_spec().name)\n",
        "    \n",
        "  def _step(self, action):\n",
        "    time_step = self._env.step(action)  \n",
        "    observation = time_step.observation.astype('float32')\n",
        "    time_step = time_step._replace(observation = observation/255.0)\n",
        "    return time_step\n",
        "\n",
        "  def observation_spec(self):\n",
        "    return self._observation_spec\n",
        "  \n",
        "  def _reset(self):\n",
        "    time_step = self._env.reset()\n",
        "    observation = time_step.observation.astype('float32')\n",
        "    time_step = time_step._replace(observation = observation/255.0)\n",
        "    return time_step"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnam98DOw7oR"
      },
      "source": [
        "environment_name = \"MsPacman-v0\"\n",
        "dir = \"drive/MyDrive/PacmanDQN\"\n",
        "\n",
        "train_py_env = suite_atari.load(\n",
        "    environment_name, \n",
        "    gym_env_wrappers = suite_atari.DEFAULT_ATARI_GYM_WRAPPERS_WITH_STACKING, \n",
        "    env_wrappers=(Normalizer,))\n",
        "\n",
        "test_py_env = suite_atari.load(\n",
        "    environment_name,\n",
        "    gym_env_wrappers = (ObservationCollector,) + suite_atari.DEFAULT_ATARI_GYM_WRAPPERS_WITH_STACKING, \n",
        "    env_wrappers = (Normalizer,))\n",
        "\n",
        "train_tf_env = tf_agents.environments.tf_py_environment.TFPyEnvironment(train_py_env)\n",
        "test_tf_env = tf_agents.environments.tf_py_environment.TFPyEnvironment(test_py_env)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKMFTfQgyIeI"
      },
      "source": [
        "global_step = tf.compat.v1.train.get_or_create_global_step()\n",
        "\n",
        "q_net = tf_agents.networks.q_network.QNetwork(\n",
        "    input_tensor_spec = train_tf_env.observation_spec(),\n",
        "    action_spec = train_tf_env.action_spec(),\n",
        "    conv_layer_params = ((32, 8, 4), (64, 4, 2), (64, 3, 1)), \n",
        "    fc_layer_params = (512,))\n",
        "\n",
        "agent = tf_agents.agents.DqnAgent(\n",
        "    train_tf_env.time_step_spec(),\n",
        "    train_tf_env.action_spec(),\n",
        "    q_network = q_net,\n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=0.0003),\n",
        "    epsilon_greedy = 0.03,\n",
        "    n_step_update = 2,\n",
        "    target_update_tau = 0.005,\n",
        "    td_errors_loss_fn = tf_agents.utils.common.element_wise_huber_loss,\n",
        "    gamma = 0.99,\n",
        "    train_step_counter = global_step)\n",
        "\n",
        "agent.initialize()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrXUcbcfyOc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cef8c32-6f06-428b-a1ec-3b93b70d68e4"
      },
      "source": [
        "replay_buffer = tf_agents.replay_buffers.tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec = agent.collect_data_spec,\n",
        "    batch_size = train_tf_env.batch_size,\n",
        "    max_length = 10000)\n",
        "\n",
        "dataset = replay_buffer.as_dataset(sample_batch_size = 64, num_steps = 3, num_parallel_calls = 3).prefetch(3)\n",
        "dataset = iter(dataset)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/operators/control_flow.py:1218: ReplayBuffer.get_next (from tf_agents.replay_buffers.replay_buffer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `as_dataset(..., single_deterministic_pass=False) instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJ3m3hur6Ot6"
      },
      "source": [
        "number_episodes_metric = tf_agents.metrics.tf_metrics.NumberOfEpisodes()\n",
        "average_return_metric = tf_agents.metrics.tf_metrics.AverageReturnMetric()\n",
        "random_policy = tf_agents.policies.random_tf_policy.RandomTFPolicy(train_tf_env.time_step_spec(), train_tf_env.action_spec())\n",
        "\n",
        "train_driver = tf_agents.drivers.dynamic_step_driver.DynamicStepDriver(\n",
        "    env = train_tf_env,\n",
        "    policy = agent.collect_policy,\n",
        "    observers = [replay_buffer.add_batch, number_episodes_metric],\n",
        "    num_steps = 10)\n",
        "\n",
        "test_driver = tf_agents.drivers.dynamic_episode_driver.DynamicEpisodeDriver(\n",
        "    env = test_tf_env,\n",
        "    policy = agent.policy,\n",
        "    observers = [average_return_metric],\n",
        "    num_episodes = 1)\n",
        "\n",
        "random_driver = tf_agents.drivers.dynamic_step_driver.DynamicStepDriver(\n",
        "    env = train_tf_env,\n",
        "    policy = random_policy,\n",
        "    observers = [replay_buffer.add_batch],\n",
        "    num_steps = 1000)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjPEYE9rL2yZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa97d5a0-6975-4249-b199-5067e02ca168"
      },
      "source": [
        "checkpoint_dir = os.path.join(os.getcwd(), f'{dir}/checkpoint')\n",
        "\n",
        "train_checkpointer = tf_agents.utils.common.Checkpointer(\n",
        "    ckpt_dir = checkpoint_dir,\n",
        "    max_to_keep = 1,\n",
        "    agent = agent,\n",
        "    policy = agent.policy,\n",
        "    replay_buffer = replay_buffer,\n",
        "    global_step = global_step)\n",
        "\n",
        "train_checkpointer.initialize_or_restore()\n",
        "global_step = tf.compat.v1.train.get_global_step()\n",
        "print(global_step)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'global_step:0' shape=() dtype=int64, numpy=1000>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFCNWjU2Q_Eu"
      },
      "source": [
        "def capture_episodes(video_filename, num_episodes = 1):\n",
        "    with imageio.get_writer(video_filename, fps = 24) as video:\n",
        "      for _ in range(num_episodes):\n",
        "        time_step = test_tf_env.reset()\n",
        "        while not time_step.is_last():\n",
        "          policy_step = agent.policy.action(time_step)\n",
        "          time_step = test_tf_env.step(policy_step.action)\n",
        "\n",
        "        for observation in test_py_env.return_observations():\n",
        "          video.append_data(observation)    "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYuvycSOwzG4"
      },
      "source": [
        "if global_step == 0:\n",
        "  random_driver.run()\n",
        "  os.makedirs(f'{dir}/videos')   \n",
        "  capture_episodes(f'{dir}/videos/no_training.mp4')\n",
        "  \n",
        "step = global_step\n",
        "time_step = train_tf_env.reset()\n",
        "agent.train = tf_agents.utils.common.function(agent.train)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeRYujYY7ILl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c0db71-f3ac-4780-84d5-9f3acea3d988"
      },
      "source": [
        "for epoch in range(step + 1, step + 100001):\n",
        "  time_step, _ = train_driver.run(time_step)\n",
        "  experience, _ = next(dataset)\n",
        "  loss, _ = agent.train(experience)\n",
        "\n",
        "  if epoch % 1000  == 0:\n",
        "    test_driver.run()\n",
        "    num_episodes = number_episodes_metric.result().numpy()\n",
        "    test_score = average_return_metric.result().numpy() \n",
        "    average_return_metric.reset()\n",
        "    capture_episodes(f'{dir}/videos/epoch_{epoch}_episode_{num_episodes+6848}_score_{test_score}.mp4')\n",
        "    train_checkpointer.save(global_step)\n",
        "    step = epoch\n",
        "    print(loss)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_agents/drivers/dynamic_step_driver.py:203: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.while_loop(c, b, vars, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tf_agents/drivers/dynamic_step_driver.py:203: calling while_loop_v2 (from tensorflow.python.ops.control_flow_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.while_loop(c, b, vars, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.while_loop(c, b, vars))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.foldr(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:201: calling foldr_v2 (from tensorflow.python.ops.functional_ops) with back_prop=False is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
            "Instead of:\n",
            "results = tf.foldr(fn, elems, back_prop=False)\n",
            "Use:\n",
            "results = tf.nest.map_structure(tf.stop_gradient, tf.foldr(fn, elems))\n",
            "WARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (210, 160) to (224, 160) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(7.343555, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (210, 160) to (224, 160) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to None (risking incompatibility). You may also see a FFMPEG warning concerning speedloss due to data not being aligned.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(13.320283, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}